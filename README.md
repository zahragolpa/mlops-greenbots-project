# Cardiovascular Disease Prediction - MLOps Level 1
This is the final project for the MLOps course held by IVADO and UdeM in Fall/Winter 2024. 

Our group, called Greenbots, worked on developing a production-ready website for predicting whether someone is at risk of cardiovascular disease. This website is empowered by a couple of technologies to achieve MLOps Level 1, which includes automatic pipelines for data preprocessing, data validation, model training, hyper-parameter tuning, model evaluation, model monitoring, pushing the model to the registry, experiment tracking, etc.

## Technical Design
Here, we share the technical design for different aspects of this product and the tools we used to achieve this. The technical design comes in three parts: Model Engineering, Model Serving, and the Automated Pipeline.

### Model Engineering
The data is extracted from the data resources on MinIO and validated using Deepchecks. The models were trained with hyper-parameter tuning using sklearn (Random Forest, Logistic Regression, SVM), and the experiments were tracked with mlflow. The best-performing model is then selected automatically and pushed to the mlflow model registry. This whole pipeline is automated using Prefect.


<img width="1580" alt="image" src="https://github.com/zahragolpa/greenbots/assets/20627999/9d82a985-2575-49c5-b7e9-7ad2b0a34585">


### Model Serving
The patient data is entered on the frontend which can talk to the backend through Flask. The backend fetches the best-performing model from the registry and has access to write the new patient data to the health record database on MinIO.


<img width="1360" alt="image" src="https://github.com/zahragolpa/greenbots/assets/20627999/d95d53ab-5d3d-488a-8fbc-60f66c2345f8">

### Automated Pipeline
Overall, the technical design consists of the frontend which is connected to the backend and is the main entry point for the user. The backend has access to the health records database and adds new inferences to the database each time a prediction is made. To serve the model, it fetches the best-performing model from mlflow model registry. The process of validating data and model, data preprocessing, training the new model, and updating the registry is done automatically through a prefect pipeline.


<img width="1542" alt="image" src="https://github.com/zahragolpa/greenbots/assets/20627999/242cbbe4-ac45-4955-b73f-39b4c1193878">


## Getting Started
To start this application, you need to have docker and docker-compose installed:
```
sudo apt install docker
sudo apt install docker-compose
```

Then, clone this repository and run the following command: 
```
docker compose up --build
```

To start the Prefect server for automated pipelines, open a new tab in your terminal and run:
```
prefect server start
```
Now, you have access to a couple of services:
- The app frontend is accessible at `localhost:6060`.
- Model registry and experiment tracking is handled by mlflow at `localhost:5000`.
- MinIO handles data storage at `localhost:31975`.
- The Prefect server runs at `localhost:4200`.
- The data validation and model validation reports generated by Deepchecks are saved to your local disk at `src/trainer/deepchecks_reports`. These reports will be generated every time a new data point is provided or the model is updated.


## Features
To run inference, open the app by navigating to `localhost:6060`. This is what the UI looks like:


<img width="100%" alt="image" src="https://github.com/zahragolpa/greenbots/assets/20627999/2f56d1cd-e963-4467-8a21-4545b158eae2">



You can either manually enter values for the new inference or upload a .csv file and run the inference on multiple instances at once. Select "Predict" and you will see the predictions as shown below:


<img width="100%" alt="image" src="https://github.com/zahragolpa/greenbots/assets/20627999/6b5beda5-3bfc-4047-9a96-03af8d24ac2e">


Now, this prediction was done based on the latest tagged model on production. If the training data gets updated, a new training job will be triggered and the model will be updated after it has passed a suite of tests performed by Deepchecks. Moreover, before starting the training job, the new data will be examined using Deepchecks. This way, we can make sure that the model and data are always reliable in terms of integrity. Here's what a Deepchecks report looks like:


![Screenshot 2024-06-18 at 11 38 01 AM](https://github.com/zahragolpa/greenbots/assets/20627999/e3b9164e-61af-4438-8449-dd953d329211)



The new model will then be pushed to the registry (mlflow) and can be tagged as the production model to be used instead of the previous model. These figures show the experiment tracking dashboard and model registry with versioning on mlflow:


![mlflow-model-versions](https://github.com/zahragolpa/greenbots/assets/20627999/8c10ad5e-9c5f-445e-9cad-53bc97a36d2b)


![mlflow-exp-tracking](https://github.com/zahragolpa/greenbots/assets/20627999/79a1d384-f7b2-4d1e-a8d0-816857277663)


The dataset lives inside a MinIO bucket and gets updated when a new inference is made using unseen data:


![Screenshot 2024-06-18 at 11 56 09 AM](https://github.com/zahragolpa/greenbots/assets/20627999/1b1e06d4-c86f-4536-81e3-5306f933ff64)


Finally, you can see the whole automated pipeline on Prefect's dashboard:


![Screenshot 2024-06-18 at 11 34 38 AM](https://github.com/zahragolpa/greenbots/assets/20627999/3e01aa6a-dea1-44a8-a012-0ed1e3a0b091)

## Next Steps
- [ ] Add data versioning with DVC
- [ ] Add prefect deployments
- [ ] Revisit the folder structures
- [ ] Add CI/CD to reach MLOps Level 2
- [ ] Add unit tests for each module
- [ ] Support more model types
- [ ] Support model monitoring with Evidently.ai





